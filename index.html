<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="Conditional Diffusion Models for Medical Image Classification">
  <meta property="og:title" content="Conditional Diffusion Models as Medical Image Classifiers"/>
  <meta property="og:description" content="Exploring explainability and uncertainty estimation in medical image classification using diffusion models."/>
  <meta property="og:url" content="https://yourwebsite.com"/>
  <meta property="og:image" content="static/images/social_banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Conditional Diffusion Models for Medical Imaging">
  <meta name="twitter:description" content="A novel approach for explainable and uncertainty-aware medical image classification using diffusion models.">
  <meta name="twitter:image" content="static/images/twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Medical Imaging, Diffusion Models, AI, Machine Learning, Explainability, Uncertainty Estimation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Conditional Diffusion Models as Medical Image Classifiers</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.cim.mcgill.ca/~faverog/" target="_blank">Gian Mario Favero</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.cim.mcgill.ca/~parhamsa/" target="_blank">Parham Saremi</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.cim.mcgill.ca/~ekacz/" target="_blank">Emily Kaczmarek</a>,</span>
                    <span class="author-block">
                      <a href="https://www.cim.mcgill.ca/~brennann/" target="_blank">Brennan Nichyporuk</a>,</span>
                      <span class="author-block">
                        <a href="https://www.cim.mcgill.ca/~arbel/#" target="_blank">Tal Arbel</a></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">McGill University, Mila - Quebec AI Institute<br>In-Review</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/Med_Diffusion_Classifier_Preprint.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/faverogian/med-diffusion-classifier" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.03687" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <img src="static/images/architecture.png" alt="Architecture"/>
      <div class="subtitle">
        <p>
          <strong>Diffusion classifiers</strong> extract implicit classifiers from conditional diffusion models. First, a sample, 
          \( \boldsymbol{x} \), is noised at a randomly chosen noise level, \( (\boldsymbol{\epsilon}_k, \lambda_k) \). The noised 
          sample is then denoised by the diffusion network with each possible conditioning input, \( c_j \). The conditioning 
          variable, \( c_j \), that results in the denoised output, 
          \( \hat{\boldsymbol{x}}_\theta (\boldsymbol{z}_\lambda, c_j) \), with the smallest reconstruction error is selected as the 
          class. This process is repeated for a set of \( N \) noise levels \( (\boldsymbol{\epsilon}, \lambda) \) with the 
          reconstruction errors aggregated (e.g., average/majority voting) for a more accurate prediction.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper Abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Discriminative classifiers have become a foundational tool in deep learning for medical imaging, excelling at learning separable features of complex data distributions. However, these models often need careful design, augmentation, and training techniques to ensure safe and reliable deployment. Recently, diffusion models have become synonymous with generative modeling in 2D. These models showcase robustness across a range of tasks including natural image classification, where classification is performed by comparing reconstruction errors across images generated for each possible conditioning input. This work presents the first exploration of the potential of class conditional diffusion models for 2D medical image classification. First, we develop a novel majority voting scheme shown to improve the performance of medical diffusion classifiers. Next, extensive experiments on the CheXpert and ISIC Melanoma skin cancer datasets demonstrate that foundation and trained-from-scratch diffusion models achieve competitive performance against SOTA discriminative classifiers without the need for explicit supervision. In addition, we show that diffusion classifiers are intrinsically explainable, and can be used to quantify the uncertainty of their predictions, increasing their trustworthiness and reliability in safety-critical, clinical contexts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Novel Majority Voting Algorithm -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column is-half">
        <h2 class="title is-3">Novel Majority Voting Algorithm</h2>
        <p>
          We propose a simple but effective majority voting scheme that, instead of cumulating errors at each timestep, tallies the amount of times a reconstruction error was smaller for each test condition and then chooses the class with the most votes. Using a majority voting scheme increases classification performance across the board, and specifically so at larger values of $N$. This result is intuitive; at greater values of $N$ there are more reconstructions attempted from high noise disturbance which can introduce large sources of variance in an average error scheme. Results here are shown for the CheXpert classification task.
        </p>
      </div>
      <div class="column is-half">
        <figure class="image is-centered">
          <img src="static/images/chexpert-step-ablation.png" alt="Majority Voting Algorithm">
        </figure>
      </div>
    </div>
  </div>
</section>

<!-- Performance vs SOTA -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column is-half">
        <figure class="image is-centered">
          <img src="static/images/classification-table.png" alt="Performance Comparison">
        </figure>
      </div>
      <div class="column is-half">
        <h2 class="title is-3">Competitive vs. SOTA Discriminative Classifiers</h2>
        <p>
          Our experiments on the CheXpert and ISIC Melanoma skin cancer datasets demonstrate that foundation and trained-from-scratch diffusion models achieve competitive performance against SOTA discriminative classifiers. Notably, diffusion classifiers achieve this performance with minimal hyperparameter tuning, no augmentations, and without being trained on a classification objective. $^*$ and $^\dagger$ denote fine-tuned and zero-shot versions, respectively. Diffusion classifier results are with 501 classification steps, and a majority vote.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Intrinsic Explainability -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column is-half">
        <h2 class="title is-3">Intrinsic Explainability</h2>
        <p>
          Importantly, diffusion classifiers are able to produce counterfactual explanations, as opposed to other interpretability methods that simply highlight regions of interest. The counterfactual image of a sick patient shows decreased disease pathology in the left and right lungs, while the factual reconstruction shows minimal differences. The natural interpretability of diffusion classifiers provides both transparency on how the model is learning (thus allowing the identification of shortcut learning), and specific class information which improves understanding of disease.
        </p>
      </div>
      <div class="column is-half">
        <figure class="image is-centered">
          <img src="static/images/explainability.png" alt="Explainability Visualization">
        </figure>
      </div>
    </div>
  </div>
</section>

<!-- Uncertainty Quantification -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered">
      <div class="column is-half">
        <figure class="image is-centered">
          <img src="static/images/uncertainty.png" alt="Uncertainty Quantification">
        </figure>
      </div>
      <div class="column is-half">
        <h2 class="title is-3">Uncertainty Quantification</h2>
        <p>
          In medical imaging, uncertainty measures are validated by confirming that when the model is confident, the prediction is correct, and when it is uncertain, it is incorrect. We therefore validate the diffusion model's uncertainty quantification by filtering out the most uncertain predictions and examining the change in performance.Each of the models show accuracy increases as the most uncertain predictions are filtered out for CheXpert (- -) and ISIC (-). This indicates that these models are most uncertain about their incorrect predictions, which confirms the effectiveness of their uncertainty measure and high value across medical applications.
        </p>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{favero2025conditionaldiffusionmodelsmedical,
        title={Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free}, 
        author={Gian Mario Favero and Parham Saremi and Emily Kaczmarek and Brennan Nichyporuk and Tal Arbel},
        year={2025},
        eprint={2502.03687},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2502.03687}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Add MathJax for LaTeX rendering -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script async src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
